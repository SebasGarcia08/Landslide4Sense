hydra:
  run:
    dir: ./

data:
  dir: ./data/
  train_list: data/train.txt
  eval_lists_paths:
    - ./data/train.txt
  eval_names:
    - train
  test_list: ./data/valid.txt
  input_size: [128, 128]
  augmentation:
    module: landslide4sense.data.augmentations
    name: transforms

model:
  restore_from: 
  module: landslide4sense.models
  name: Unet
  args:
    n_classes: 2

optimizer:
  restore_from:
  module: torch.optim
  name: SGD
  args:
    lr: 0.01
    weight_decay: 0.0005
    momentum: 0.9
  scheduler:
    module: torch_poly_lr_decay
    name: PolynomialLRDecay
    args:
      end_learning_rate: 0.0001
      max_decay_steps: 100_000
      power: 0.9


loss:
  module: torch.nn
  name: TverskyLoss
  args:
    mode: multiclass
    classes: 2
    ignore_index: 255
    log_loss: True
    alpha: 0.7
    beta: 0.3

train:
  start_epoch: 0
  steps_per_epoch: 30
  batch_size: 128
  num_workers: 4
  num_steps: 100_000
  num_steps_stop: 100_000
  gpu_id: 0
  snapshot_dir: ./models/
  results_filename: train_results.json
  seed: 42
  callbacks:
    early_stopping:
      monitor: train_f1
      mode: max
      patience: 10
      best_result: 0.5
    wandb:
      project: "landslide4sense"
      name: back-to-basics
      group: segformer
      tags:
        - val_split
        - spatial_data_aug
        - non_spatial_data_aug

calibrate:
  model_filename: best_model.pth
  data_path: data/train.txt
  results_filename: calibrate_results.json
  num_thresholds: 100

predict:
  snapshot_dir: ./submissions/
