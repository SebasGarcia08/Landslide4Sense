hydra:
  run:
    dir: ./

data:
  dir: ./data/
  train_list: data/train.txt
  eval_lists_paths:
    - ./data/train.txt
  eval_names:
    - train
  test_list: ./data/valid.txt
  input_size: [128, 128]
  augmentation:
    module: landslide4sense.data.augmentations
    name: transforms

model:
  restore_from: 
  module: landslide4sense.models
  name: SegFormer
  args:
    in_channels: 14
    num_classes: 2  
    widths: [64, 128, 256, 512]
    depths: [3, 4, 6, 3]
    all_num_heads: [1, 2, 4, 8]
    patch_sizes: [7, 3, 3, 3]
    overlap_sizes: [4, 2, 2, 2]
    reduction_ratios: [32, 16, 8, 4, 2, 1]
    mlp_expansions: [4, 4, 4, 4]
    decoder_channels: 256
    scale_factors: [16, 8, 4, 2, 1]

optimizer:
  restore_from:
  module: torch.optim
  name: AdamW
  args:
    lr: 0.0001
    weight_decay: 0.0001
  scheduler:
    module: torch_poly_lr_decay
    name: PolynomialLRDecay
    args:
      end_learning_rate: 0.000001
      max_decay_steps: 100_000
      power: 0.9


loss:
  module: torch.nn
  name: CrossEntropyLoss
  args:
    ignore_index: 255

train:
  start_epoch: 0
  steps_per_epoch: 120
  batch_size: 32
  num_workers: 4
  num_steps: 100_000
  num_steps_stop: 100_000
  gpu_id: 0
  snapshot_dir: ./models/
  results_filename: train_results.json
  seed: 42
  callbacks:
    early_stopping:
      monitor: train_f1
      mode: max
      patience: 10
      best_result: 0.5
    wandb:
      project: "landslide4sense"
      name: seg-life-test
      group: segformer
      tags:
        - val_split
        - spatial_data_aug
        - non_spatial_data_aug

calibrate:
  model_filename: best_model.pth
  data_path: data/train.txt
  results_filename: calibrate_results.json
  num_thresholds: 100

predict:
  snapshot_dir: ./submissions/
